import os
import torch
from torchvision import transforms as T
import numpy as np
import random  # äº‚æ•¸æ§åˆ¶
import argparse  # å‘½ä»¤åˆ—åƒæ•¸è™•ç†
from data_loader import MVTecDRAEM_Test_Visual_Dataset
from model_unet import ReconstructiveSubNetwork, DiscriminativeSubNetwork
import torchvision.transforms as transforms
import cv2
from PIL import Image  # é›–ç„¶ transform ç”¨åˆ°äº†ï¼Œä½†ç›´æ¥ç”¨ cv2 è®€å¯«æ›´ä¸€è‡´
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt


def setup_seed(seed):
    # è¨­å®šéš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿å¯¦é©—å¯é‡ç¾
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True  # ä¿è­‰çµæœå¯é‡ç¾
    torch.backends.cudnn.benchmark = False  # é—œé–‰è‡ªå‹•æœ€ä½³åŒ–æœå°‹


# =======================
# Utilities
# =======================
def get_available_gpu():
    """è‡ªå‹•é¸æ“‡è¨˜æ†¶é«”ä½¿ç”¨ç‡æœ€ä½çš„GPU"""
    if not torch.cuda.is_available():
        return -1  # æ²’æœ‰GPUå¯ç”¨

    gpu_count = torch.cuda.device_count()
    if gpu_count == 0:
        return -1

    # æª¢æŸ¥æ¯å€‹GPUçš„è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
    gpu_memory = []
    for i in range(gpu_count):
        torch.cuda.set_device(i)
        memory_allocated = torch.cuda.memory_allocated(i)
        # memory_reserved = torch.cuda.memory_reserved(i) # é€™å€‹åœ¨æŸäº›æƒ…æ³ä¸‹æœƒé¡¯ç¤ºè¼ƒé«˜ï¼Œæˆ‘å€‘æ›´é—œæ³¨å·²åˆ†é…çš„
        gpu_memory.append((i, memory_allocated))  # åªç”¨ allocated

    # é¸æ“‡è¨˜æ†¶é«”ä½¿ç”¨æœ€å°‘çš„GPU
    available_gpu = min(gpu_memory, key=lambda x: x[1])[0]
    return available_gpu


# =======================
# Main Pipeline
# =======================
def main(obj_names, args):
    setup_seed(111)  # å›ºå®šéš¨æ©Ÿç¨®å­
    device = "cuda" if torch.cuda.is_available() else "cpu"
    # å»ºç«‹ä¸»å­˜æª”è³‡æ–™å¤¾
    save_root = "./inference_results"  # æ¨ç†çµæœé€šå¸¸ä¿å­˜åœ¨ä¸åŒçš„ç›®éŒ„
    if not os.path.exists(save_root):
        os.makedirs(save_root)
    print("ğŸ”„ é–‹å§‹æ¸¬è©¦ï¼Œå…±æœ‰ç‰©ä»¶é¡åˆ¥:", len(obj_names))
    for obj_name in obj_names:
        img_dim = 256
        teacher_model = ReconstructiveSubNetwork(in_channels=3,
                                                 out_channels=3,
                                                 base_width=128)
        # recon_path = f'./DRAEM_checkpoints/DRAEM_seg_large_ae_large_0.0001_800_bs8_' + obj_name + '_'
        # checkpoint_path = recon_path + ".pckl"
        # teacher_recon_ckpt = torch.load(checkpoint_path,
        model_best_recon_weights_path = './DRAEM_checkpoints/DRAEM_seg_large_ae_large_0.0001_800_bs8_' + obj_name + '_recon_path.pckl'  # â¬…ï¸ æˆ‘çš„çš„æ¬Šé‡è·¯å¾‘
        if not os.path.exists(model_best_recon_weights_path):
            print(
                f"âŒ éŒ¯èª¤: æœªæ‰¾åˆ°æ¨¡å‹æ¬Šé‡æª”æ¡ˆ: {model_best_recon_weights_path}ï¼Œè«‹æª¢æŸ¥è·¯å¾‘æˆ–è¨“ç·´æ˜¯å¦å®Œæˆã€‚"
            )
            continue

        teacher_model.load_state_dict(
            torch.load(model_best_recon_weights_path, map_location=device))
        teacher_model.cuda()
        teacher_model.eval()

        student_seg_model = DiscriminativeSubNetwork(in_channels=6,
                                                     out_channels=2,
                                                     base_channels=64)
        # seg_path = f'./DRAEM_checkpoints/DRAEM_seg_large_ae_large_0.0001_800_bs8_' + obj_name + '__seg'
        # checkpoint_seg_path = seg_path + ".pckl"
        # teacher_seg_ckpt = torch.load(checkpoint_seg_path,
        model_best_seg_weights_path = './DRAEM_checkpoints/DRAEM_seg_large_ae_large_0.0001_800_bs8_' + obj_name + '__seg.pckl'  # â¬…ï¸ æˆ‘çš„çš„æ¬Šé‡è·¯å¾‘
        if not os.path.exists(model_best_seg_weights_path):
            print(
                f"âŒ éŒ¯èª¤: æœªæ‰¾åˆ°æ¨¡å‹æ¬Šé‡æª”æ¡ˆ: {model_best_seg_weights_path}ï¼Œè«‹æª¢æŸ¥è·¯å¾‘æˆ–è¨“ç·´æ˜¯å¦å®Œæˆã€‚"
            )
            continue

        student_seg_model.load_state_dict(
            torch.load(model_best_seg_weights_path, map_location=device))
        student_seg_model.cuda()
        student_seg_model.eval()

        # å»ºç«‹è³‡æ–™é›†å’Œè³‡æ–™è¼‰å…¥å™¨
        try:
            path = args.mvtec_root + "/" + obj_name + "/test/"
            print(f"ğŸ“‚ è¼‰å…¥è³‡æ–™é›†è·¯å¾‘:{path}")

            # æ£€æŸ¥testç›®å½•ä¸‹çš„å­ç›®å½•
            subdirs = ['broken_large', 'broken_small', 'contamination', 'good']
            existing_subdirs = []

            for subdir in subdirs:
                subdir_path = os.path.join(path, subdir)
                if os.path.exists(subdir_path) and os.path.isdir(subdir_path):
                    existing_subdirs.append(subdir)
                    print(f"âœ… æ‰¾åˆ°é¡åˆ¥: {subdir}")

            if not existing_subdirs:
                raise Exception(f"åœ¨ {path} ä¸­æœªæ‰¾åˆ°ä»»ä½•æ¸¬è©¦é¡åˆ¥ç›®éŒ„")

            dataset = MVTecDRAEM_Test_Visual_Dataset(
                path, resize_shape=[img_dim, img_dim])

            dataloader = DataLoader(dataset,
                                    batch_size=1,
                                    shuffle=False,
                                    num_workers=0)

        except Exception as e:
            print(f"âŒ éŒ¯èª¤: {e}")

        print(f"ğŸ“Š è³‡æ–™é›†å¤§å°: {len(dataset)} å¼µåœ–ç‰‡")

        total_pixel_scores = np.zeros((img_dim * img_dim * len(dataset)))
        total_gt_pixel_scores = np.zeros((img_dim * img_dim * len(dataset)))
        mask_cnt = 0

        anomaly_score_gt = []
        anomaly_score_prediction = []

        display_images = torch.zeros((16, 3, 256, 256)).cuda()
        display_gt_images = torch.zeros((16, 3, 256, 256)).cuda()
        display_out_masks = torch.zeros((16, 1, 256, 256)).cuda()
        display_in_masks = torch.zeros((16, 1, 256, 256)).cuda()
        cnt_display = 0
        display_indices = np.random.randint(len(dataloader), size=(16, ))

        for i_batch, sample_batched in enumerate(dataloader):
            # å»ºç«‹è©²é¡åˆ¥çš„è¼¸å‡ºè³‡æ–™å¤¾
            output_dir = os.path.join(save_root, obj_name)
            print(f"ğŸ“‚ è¼‰è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘:{output_dir}")
            os.makedirs(output_dir, exist_ok=True)  # ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨

            gray_batch = sample_batched["image"].cuda()

            # ç²å–åŸå§‹åœ–åƒï¼ˆç”¨æ–¼é¡¯ç¤ºï¼‰
            original_image = gray_batch.permute(0, 2, 3, 1).cpu().numpy()[0]
            # æ­£è¦åŒ–åˆ° [0, 1] ç¯„åœ
            original_image = (original_image - original_image.min()) / (
                original_image.max() - original_image.min())

            is_normal = sample_batched["has_anomaly"].detach().numpy()[0, 0]
            anomaly_score_gt.append(is_normal)
            true_mask = sample_batched["mask"]
            true_mask_cv = true_mask.detach().numpy()[0, :, :, :].transpose(
                (1, 2, 0))

            gray_rec = teacher_model(gray_batch)
            joined_in = torch.cat((gray_rec.detach(), gray_batch), dim=1)

            out_mask = student_seg_model(joined_in)
            out_mask_sm = torch.softmax(out_mask, dim=1)

            if i_batch in display_indices:
                t_mask = out_mask_sm[:, 1:, :, :]
                display_images[cnt_display] = gray_rec[0].cpu().detach()
                display_gt_images[cnt_display] = gray_batch[0].cpu().detach()
                display_out_masks[cnt_display] = t_mask[0].cpu().detach()
                display_in_masks[cnt_display] = true_mask[0].cpu().detach()
                cnt_display += 1

            out_mask_cv = out_mask_sm[0, 1, :, :].detach().cpu().numpy()
            save_path_base = os.path.join(output_dir, obj_name)

            # åœ¨åŒä¸€å€‹pltä¸­é¡¯ç¤ºåŸåœ–å’Œç•°å¸¸ç†±åœ–
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

            # é¡¯ç¤ºåŸåœ–
            ax1.imshow(original_image)
            ax1.set_title('Original Image')
            ax1.axis('off')

            # é¡¯ç¤ºç•°å¸¸ç†±åœ–
            im = ax2.imshow(out_mask_cv, cmap='hot')
            ax2.set_title('Predicted Anomaly Heatmap')
            ax2.axis('off')

            # æ·»åŠ é¡è‰²æ¢
            plt.colorbar(im, ax=ax2, fraction=0.046, pad=0.04)

            plt.tight_layout()

            # å­˜æª”
            save_path_combined = f"{save_path_base}_combined_{str(i_batch)}.png"
            plt.savefig(save_path_combined,
                        dpi=300,
                        bbox_inches='tight',
                        pad_inches=0.1)
            print(f"Combined image saved to: {save_path_combined}")

            plt.show()
            plt.close()  # é—œé–‰åœ–å½¢ä»¥é‡‹æ”¾è¨˜æ†¶é«”

            out_mask_averaged = torch.nn.functional.avg_pool2d(
                out_mask_sm[:, 1:, :, :], 21, stride=1,
                padding=21 // 2).cpu().detach().numpy()
            image_score = np.max(out_mask_averaged)

            anomaly_score_prediction.append(image_score)

            flat_true_mask = true_mask_cv.flatten()
            flat_out_mask = out_mask_cv.flatten()
            total_pixel_scores[mask_cnt * img_dim * img_dim:(mask_cnt + 1) *
                               img_dim * img_dim] = flat_out_mask
            total_gt_pixel_scores[mask_cnt * img_dim * img_dim:(mask_cnt + 1) *
                                  img_dim * img_dim] = flat_true_mask
            mask_cnt += 1
        print(f"\nâœ… ç‰©ä»¶é¡åˆ¥ {obj_name} æ¸¬è©¦å®Œæˆï¼")
    print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦å·²å®Œæˆï¼")


# =======================
# Run pipeline
# =======================
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--obj_id', action='store', type=int, required=True)
    parser.add_argument('--gpu_id',
                        action='store',
                        type=int,
                        default=-2,
                        required=False,
                        help='GPU ID (-2: auto-select, -1: CPU)')
    parser.add_argument('--mvtec_root',
                        type=str,
                        default='./mvtec',
                        help='Path to the MVTec dataset root directory')
    parser.add_argument('--checkpoint_dir',
                        type=str,
                        default='./save_files',
                        help='Directory to load model checkpoints')

    args = parser.parse_args()

    # è‡ªå‹•é¸æ“‡GPU
    if args.gpu_id == -2:  # è‡ªå‹•é¸æ“‡æ¨¡å¼
        args.gpu_id = get_available_gpu()
        print(f"è‡ªå‹•é¸æ“‡ GPU: {args.gpu_id}")

    obj_batch = [['capsule'], ['bottle'], ['carpet'], ['leather'], ['pill'],
                 ['transistor'], ['tile'], ['cable'], ['zipper'],
                 ['toothbrush'], ['metal_nut'], ['hazelnut'], ['screw'],
                 ['grid'], ['wood']]

    if int(args.obj_id) == -1:
        obj_list = [
            'capsule', 'bottle', 'carpet', 'leather', 'pill', 'transistor',
            'tile', 'cable', 'zipper', 'toothbrush', 'metal_nut', 'hazelnut',
            'screw', 'grid', 'wood'
        ]
        picked_classes = obj_list
    else:
        picked_classes = obj_batch[int(args.obj_id)]

    # æ ¹æ“šé¸æ“‡çš„GPUåŸ·è¡Œ
    if args.gpu_id == -1:
        # ä½¿ç”¨CPU
        main(picked_classes, args)
    else:
        # ä½¿ç”¨GPU
        with torch.cuda.device(args.gpu_id):
            main(picked_classes, args)
